{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "-G4bZhehAuXx"
            },
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from PIL import Image\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "import torchvision\n",
                "import torchvision.transforms as transforms\n",
                "from torchvision.models import resnet18\n",
                "\n",
                "from torch.utils.data import DataLoader, Subset\n",
                "from torchvision.datasets import ImageFolder\n",
                "from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop, RandomCrop, RandomHorizontalFlip, ColorJitter, Normalize\n",
                "from sklearn.model_selection import train_test_split\n",
                "from tqdm import tqdm\n",
                "\n",
                "import os\n",
                "import random"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "KFnX37_JHg36"
            },
            "outputs": [],
            "source": [
                "data_dir = \"dataset/RealWaste\"\n",
                "\n",
                "total_images = sum([len(files) for _, _, files in os.walk(data_dir)])\n",
                "print(f\"Total images: {total_images}\")\n",
                "\n",
                "dataset = ImageFolder(root=data_dir, transform=ToTensor())\n",
                "\n",
                "# Get indices for each class\n",
                "class_indices = {i: [] for i in range(len(dataset.classes))}\n",
                "for idx, (_, label) in enumerate(dataset.samples):\n",
                "    class_indices[label].append(idx)\n",
                "\n",
                "# Split into train/val/test maintaining class balance\n",
                "train_indices = []\n",
                "val_indices = []\n",
                "test_indices = []\n",
                "\n",
                "for label, indices in class_indices.items():\n",
                "    # First split into train and temp (val+test)\n",
                "    train_idx, temp_idx = train_test_split(\n",
                "        indices, train_size=0.8, random_state=42, stratify=[label]*len(indices)\n",
                "    )\n",
                "    # Then split temp into val and test\n",
                "    val_idx, test_idx = train_test_split(\n",
                "        temp_idx, train_size=0.5, random_state=42, stratify=[label]*len(temp_idx)\n",
                "    )\n",
                "    train_indices.extend(train_idx)\n",
                "    val_indices.extend(val_idx)\n",
                "    test_indices.extend(test_idx)\n",
                "\n",
                "# Create subsets\n",
                "train_dataset = Subset(dataset, train_indices)\n",
                "val_dataset = Subset(dataset, val_indices)\n",
                "test_dataset = Subset(dataset, test_indices)\n",
                "\n",
                "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "gQhZvf-kJ_B6"
            },
            "outputs": [],
            "source": [
                "# Normalization statistics\n",
                "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
                "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
                "\n",
                "# Augmentation for training\n",
                "train_transforms = Compose([\n",
                "    Resize(256),                      # Resize to 256\n",
                "    RandomCrop(224),                  # Random crop to 224x224\n",
                "    RandomHorizontalFlip(p=0.5),      # Horizontal flip\n",
                "    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1), # Color jitter\n",
                "    ToTensor(),\n",
                "    Normalize(IMAGENET_MEAN, IMAGENET_STD)  # Normalization\n",
                "])\n",
                "\n",
                "# Transforms for val/test (no augmentation)\n",
                "val_test_transforms = Compose([\n",
                "    Resize(256),\n",
                "    CenterCrop(224),                  # Center crop\n",
                "    ToTensor(),\n",
                "    Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
                "])\n",
                "\n",
                "# Apply transforms\n",
                "train_dataset.dataset.transform = train_transforms\n",
                "val_dataset.dataset.transform = val_test_transforms\n",
                "test_dataset.dataset.transform = val_test_transforms\n",
                "\n",
                "# Create DataLoaders\n",
                "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
                "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
                "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "0X4MaaTbLVLR"
            },
            "outputs": [],
            "source": [
                "# Defines the model ensuring consistency with model.py\n",
                "class WasteClassifier(nn.Module):\n",
                "    def __init__(self, num_classes=9, weights='DEFAULT'):\n",
                "        super().__init__()\n",
                "        # Use weights instead of pretrained=True to avoid deprecation warnings\n",
                "        self.backbone = resnet18(weights=weights)\n",
                "        # Replace the last layer\n",
                "        in_features = self.backbone.fc.in_features\n",
                "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.backbone(x)\n",
                "\n",
                "model = WasteClassifier(num_classes=9)\n",
                "if torch.cuda.is_available():\n",
                "    model = model.cuda()  # Move to GPU"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "nq7U3xe0QvE7"
            },
            "outputs": [],
            "source": [
                "# Calculate class weights\n",
                "class_counts = [len(indices) for indices in class_indices.values()]\n",
                "total_samples = sum(class_counts)\n",
                "class_weights = [total_samples / count for count in class_counts]\n",
                "\n",
                "# Convert to tensor\n",
                "weights_tensor = torch.FloatTensor(class_weights)\n",
                "if torch.cuda.is_available():\n",
                "    weights_tensor = weights_tensor.cuda()\n",
                "\n",
                "# Use weighted loss\n",
                "criterion = nn.CrossEntropyLoss(weight=weights_tensor)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "GVa2veLSQ5-U"
            },
            "outputs": [],
            "source": [
                "# Hyperparameters\n",
                "EPOCHS = 25\n",
                "LEARNING_RATE = 0.001\n",
                "\n",
                "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3)\n",
                "\n",
                "best_val_acc = 0\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    # Train\n",
                "    model.train()\n",
                "    train_loss = 0\n",
                "    train_correct = 0\n",
                "\n",
                "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} - Train'):\n",
                "        if torch.cuda.is_available():\n",
                "            images, labels = images.cuda(), labels.cuda()\n",
                "\n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(images)\n",
                "        loss = criterion(outputs, labels)\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "\n",
                "        train_loss += loss.item()\n",
                "        train_correct += (outputs.argmax(1) == labels).sum().item()\n",
                "\n",
                "    train_acc = train_correct / len(train_dataset)\n",
                "\n",
                "    # Validation\n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    val_correct = 0\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} - Val'):\n",
                "            if torch.cuda.is_available():\n",
                "                images, labels = images.cuda(), labels.cuda()\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "\n",
                "            val_loss += loss.item()\n",
                "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
                "\n",
                "    val_acc = val_correct / len(val_dataset)\n",
                "    scheduler.step(val_loss)\n",
                "\n",
                "    print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, '\n",
                "          f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
                "\n",
                "    # Save the best model\n",
                "    if val_acc > best_val_acc:\n",
                "        best_val_acc = val_acc\n",
                "        torch.save(model.state_dict(), 'best_waste_model.pth')\n",
                "        print(f'New best model saved with accuracy: {val_acc:.4f}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}