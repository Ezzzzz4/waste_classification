{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Model Evaluation\n",
    "\n",
    "This notebook evaluates the `WasteClassifier` model trained on the RealWaste dataset. \n",
    "It includes visualizations of predictions, confusion matrices, and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Definition and Loading\n",
    "We reconstruct the model architecture used during training and load the best saved weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WasteClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=9, pretrained=False):\n",
    "        super().__init__()\n",
    "        # usage of weights instead of pretrained=True to avoid potential warnings if libraries updated\n",
    "        self.backbone = models.resnet18(weights=None) \n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Initialize model\n",
    "model = WasteClassifier(num_classes=9)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load weights\n",
    "weights_path = 'best_waste_model.pth'\n",
    "if os.path.exists(weights_path):\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "    print(\"Model weights loaded successfully!\")\n",
    "else:\n",
    "    print(f\"Warning: {weights_path} not found. Please ensure the model file exists.\")\n",
    "    \n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset and Transforms\n",
    "We define the validation transforms and dataset classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines classes based on directory structure (Alphabetical order by default in ImageFolder)\n",
    "data_dir = \"dataset/RealWaste\"\n",
    "classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "print(f\"Classes found: {classes}\")\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Create dataset reference\n",
    "full_dataset = ImageFolder(root=data_dir, transform=val_transforms)\n",
    "\n",
    "# note: the original split was random. \n",
    "# For specific evaluation, we can just grab a random subset or use the whole thing if small enough.\n",
    "# Here we'll take a subset for quicker demonstration of evaluation.\n",
    "indices = list(range(len(full_dataset)))\n",
    "random.shuffle(indices)\n",
    "eval_subset_indices = indices[:500] # Evaluate on 500 images\n",
    "eval_dataset = Subset(full_dataset, eval_subset_indices)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visual Predictions\n",
    "Let's see the model in action by predicting on random images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "    tensor = tensor.clone().detach().cpu()\n",
    "    for t, m, s in zip(tensor, IMAGENET_MEAN, IMAGENET_STD):\n",
    "        t.mul_(s).add_(m)\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    return tensor.permute(1, 2, 0).numpy()\n",
    "\n",
    "def visualize_predictions(dataset, model, num_images=6):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    indices = random.sample(range(len(dataset)), num_images)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, label = dataset[idx]\n",
    "        \n",
    "        # Prediction\n",
    "        with torch.no_grad():\n",
    "            input_tensor = image.unsqueeze(0).to(device)\n",
    "            output = model(input_tensor)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            predicted_idx = predicted.item()\n",
    "            \n",
    "        # Plotting\n",
    "        ax = axes[i]\n",
    "        img_display = denormalize(image)\n",
    "        ax.imshow(img_display)\n",
    "        \n",
    "        color = 'green' if predicted_idx == label else 'red'\n",
    "        ax.set_title(f\"True: {classes[label]}\\nPred: {classes[predicted_idx]}\", color=color, fontsize=12, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(full_dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quantitative Evaluation\n",
    "Confusion Matrix and Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Evaluating...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "y_true, y_pred = evaluate_model(model, eval_loader)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
