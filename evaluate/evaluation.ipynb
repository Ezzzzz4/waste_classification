{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Model Evaluation\n",
    "\n",
    "This notebook evaluates the `WasteClassifier` model trained on the mix of Realwaste and Trashnet datasets. \n",
    "It includes visualizations of predictions with Grad-CAM heatmaps, confusion matrices, and accuracy metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m parent_dir = os.path.dirname(current_dir)\n\u001b[32m     18\u001b[39m sys.path.append(parent_dir)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgradcam\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GradCAM\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Set device\u001b[39;00m\n\u001b[32m     23\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Fix path to import model from parent directory\n",
    "current_dir = os.path.dirname(os.path.abspath(''))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.gradcam import GradCAM\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model Definition and Loading\n",
    "We reconstruct the model architecture used during training and load the best saved weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WasteClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=9, pretrained=False):\n",
    "        super().__init__()\n",
    "        # usage of weights instead of pretrained=True to avoid potential warnings if libraries updated\n",
    "        self.backbone = models.resnet18(weights=None) \n",
    "        in_features = self.backbone.fc.in_features\n",
    "        self.backbone.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "# Initialize model\n",
    "model = WasteClassifier(num_classes=9)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load weights\n",
    "weights_path = '../pretrained/best_waste_model.pth'\n",
    "if os.path.exists(weights_path):\n",
    "    model.load_state_dict(torch.load(weights_path, map_location=device))\n",
    "    print(\"Model weights loaded successfully!\")\n",
    "else:\n",
    "    print(f\"Warning: {weights_path} not found. Please ensure the model file exists.\")\n",
    "    \n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Dataset and Transforms\n",
    "We define the validation transforms and dataset classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines classes based on directory structure (Alphabetical order by default in ImageFolder)\n",
    "data_dir = \"../dataset\"\n",
    "classes = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])\n",
    "print(f\"Classes found: {classes}\")\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Create dataset reference\n",
    "full_dataset = ImageFolder(root=data_dir, transform=val_transforms)\n",
    "\n",
    "# note: the original split was random. \n",
    "# For specific evaluation, we can just grab a random subset or use the whole thing if small enough.\n",
    "# Here we'll take a subset for quicker demonstration of evaluation.\n",
    "indices = list(range(len(full_dataset)))\n",
    "random.shuffle(indices)\n",
    "eval_subset_indices = indices[:500] # Evaluate on 500 images\n",
    "eval_dataset = Subset(full_dataset, eval_subset_indices)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visual Predictions with Grad-CAM\n",
    "Let's see the model in action by predicting on random images and overlaying Grad-CAM heatmaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "    tensor = tensor.clone().detach().cpu()\n",
    "    for t, m, s in zip(tensor, IMAGENET_MEAN, IMAGENET_STD):\n",
    "        t.mul_(s).add_(m)\n",
    "    tensor = torch.clamp(tensor, 0, 1)\n",
    "    return tensor.permute(1, 2, 0).numpy()\n",
    "\n",
    "def visualize_predictions(dataset, model, num_images=6):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    indices = random.sample(range(len(dataset)), num_images)\n",
    "    \n",
    "    # Initialize GradCAM\n",
    "    target_layer = model.backbone.layer4[-1]\n",
    "    grad_cam = GradCAM(model, target_layer)\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        image, label = dataset[idx]\n",
    "        \n",
    "        # Prediction\n",
    "        input_tensor = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Generate CAM\n",
    "        cam = grad_cam.generate_cam(input_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            predicted_idx = predicted.item()\n",
    "            \n",
    "        # Plotting\n",
    "        ax = axes[i]\n",
    "        img_display_np = denormalize(image)\n",
    "        img_display_pil = Image.fromarray((img_display_np * 255).astype(np.uint8))\n",
    "        \n",
    "        # Overlay\n",
    "        overlayed = grad_cam.overlay_heatmap(img_display_pil, cam, alpha=0.5)\n",
    "        \n",
    "        ax.imshow(overlayed)\n",
    "        \n",
    "        color = 'green' if predicted_idx == label else 'red'\n",
    "        ax.set_title(f\"True: {classes[label]}\\nPred: {classes[predicted_idx]}\", color=color, fontsize=12, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(full_dataset, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quantitative Evaluation\n",
    "Confusion Matrix and Classification Report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Evaluating...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            \n",
    "    return np.array(all_labels), np.array(all_preds)\n",
    "\n",
    "y_true, y_pred = evaluate_model(model, eval_loader)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=classes))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
