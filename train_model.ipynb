{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Waste Classification Training Pipeline\n",
                "**Architecture**: EfficientNet-B0  \n",
                "**Objective**: Robust classification of 9 waste categories using a Composite Augmentation Strategy.\n",
                "\n",
                "## Methodology\n",
                "To address real-world challenges such as distinguishing **White Metal Cans** from **White Paper**, this pipeline implements a specialized data augmentation strategy that targets specific material properties:\n",
                "\n",
                "1.  **Scale Invariance**: `RandomAffine` ensures the model recognizes objects at various zoom levels (close-ups vs far shots).\n",
                "2.  **Material Sheen**: `ColorJitter` allows the model to learn specular highlights (shine) characteristic of metal.\n",
                "3.  **Structural Learning**: `RandomGrayscale` forces the model to rely on object geometry rather than just color.\n",
                "4.  **Texture Enhancement**: `RandomAdjustSharpness` emphasizes edges and creases, critical for identifying crumpled paper."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "from PIL import Image\n",
                "import os\n",
                "import random\n",
                "from tqdm import tqdm\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights\n",
                "from torchvision.datasets import ImageFolder\n",
                "from torchvision.transforms import Compose, ToTensor, Resize, CenterCrop, RandomCrop, Normalize, RandomHorizontalFlip, RandomRotation, RandomGrayscale, RandomAdjustSharpness, RandomAutocontrast, RandomAffine, ColorJitter\n",
                "from torch.utils.data import DataLoader, Subset\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Check device\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "print(f\"Using device: {device}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Initialization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "data_dir = \"dataset\"\n",
                "total_images = sum([len(files) for _, _, files in os.walk(data_dir)])\n",
                "print(f\"Total images found: {total_images}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Composite Augmentation Pipeline\n",
                "The augmentation strategy is order-dependent to avoid artifacts (e.g., black borders from rotation) and maximize feature diversity."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ImageNet Normalization Stats\n",
                "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
                "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
                "\n",
                "train_transforms = Compose([\n",
                "    # 1. Geometric Transformations\n",
                "    # Applied before cropping to minimize 'void' (black) regions\n",
                "    Resize(256),\n",
                "    RandomRotation(degrees=180),\n",
                "    RandomAffine(degrees=0, translate=None, scale=(0.8, 1.2)), # Scale Invariance (0.8x - 1.2x)\n",
                "    \n",
                "    # 2. Patch Extraction\n",
                "    RandomCrop(224),\n",
                "    RandomHorizontalFlip(p=0.5),\n",
                "\n",
                "    # 3. Material Property Augmentation\n",
                "    # Preserves specular highlights (Metal vs Paper)\n",
                "    ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
                "    \n",
                "    # 4. Structural Augmentation\n",
                "    # Forces learning of shape/geometry (p=0.3)\n",
                "    RandomGrayscale(p=0.3),\n",
                "\n",
                "    # 5. Texture Enhancement\n",
                "    # Emphasizes creases and high-frequency details (Paper Texture)\n",
                "    RandomAdjustSharpness(sharpness_factor=1.5, p=0.3),\n",
                "    RandomAutocontrast(p=0.3),\n",
                "    \n",
                "    ToTensor(),\n",
                "    Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
                "])\n",
                "\n",
                "val_test_transforms = Compose([\n",
                "    Resize(256),\n",
                "    CenterCrop(224),\n",
                "    ToTensor(),\n",
                "    Normalize(IMAGENET_MEAN, IMAGENET_STD)\n",
                "])\n",
                "\n",
                "# Dataset Wrapper\n",
                "class TransformedDataset(torch.utils.data.Dataset):\n",
                "    def __init__(self, subset, transform=None):\n",
                "        self.subset = subset\n",
                "        self.transform = transform\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        x, y = self.subset[idx]\n",
                "        if self.transform:\n",
                "            x = self.transform(x)\n",
                "        return x, y\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.subset)\n",
                "\n",
                "# Split Strategy\n",
                "base_dataset = ImageFolder(root=data_dir, transform=None)\n",
                "\n",
                "# Stratified Split (80% Train, 10% Val, 10% Test)\n",
                "class_indices = {i: [] for i in range(len(base_dataset.classes))}\n",
                "for idx, (_, label) in enumerate(base_dataset.samples):\n",
                "    class_indices[label].append(idx)\n",
                "\n",
                "train_indices = []\n",
                "val_indices = []\n",
                "test_indices = []\n",
                "\n",
                "for label, indices in class_indices.items():\n",
                "    train_idx, temp_idx = train_test_split(\n",
                "        indices, train_size=0.8, random_state=42, stratify=[label]*len(indices)\n",
                "    )\n",
                "    val_idx, test_idx = train_test_split(\n",
                "        temp_idx, train_size=0.5, random_state=42, stratify=[label]*len(temp_idx)\n",
                "    )\n",
                "    train_indices.extend(train_idx)\n",
                "    val_indices.extend(val_idx)\n",
                "    test_indices.extend(test_idx)\n",
                "\n",
                "train_dataset = TransformedDataset(Subset(base_dataset, train_indices), train_transforms)\n",
                "val_dataset = TransformedDataset(Subset(base_dataset, val_indices), val_test_transforms)\n",
                "test_dataset = TransformedDataset(Subset(base_dataset, test_indices), val_test_transforms)\n",
                "\n",
                "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
                "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
                "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
                "\n",
                "print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, Test: {len(test_dataset)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Regularization (Mixup)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def mixup_data(x, y, alpha=0.2, use_cuda=True):\n",
                "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
                "    if alpha > 0:\n",
                "        lam = np.random.beta(alpha, alpha)\n",
                "    else:\n",
                "        lam = 1\n",
                "\n",
                "    batch_size = x.size()[0]\n",
                "    if use_cuda:\n",
                "        index = torch.randperm(batch_size).cuda()\n",
                "    else:\n",
                "        index = torch.randperm(batch_size)\n",
                "\n",
                "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
                "    y_a, y_b = y, y[index]\n",
                "    return mixed_x, y_a, y_b, lam\n",
                "\n",
                "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
                "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Model Definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class WasteClassifier(nn.Module):\n",
                "    def __init__(self, num_classes=9):\n",
                "        super().__init__()\n",
                "        weights = EfficientNet_B0_Weights.DEFAULT\n",
                "        self.backbone = efficientnet_b0(weights=weights)\n",
                "        \n",
                "        # Replace classifier head for 9 classes\n",
                "        original_in_features = self.backbone.classifier[1].in_features\n",
                "        self.backbone.classifier[1] = nn.Linear(original_in_features, num_classes)\n",
                "\n",
                "    def forward(self, x):\n",
                "        return self.backbone(x)\n",
                "\n",
                "model = WasteClassifier(num_classes=9)\n",
                "model = model.to(device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Training Loop\n",
                "Includes Class Weighting, Label Smoothing, and Checkpointing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle Class Imbalance\n",
                "class_counts = [len(indices) for indices in class_indices.values()]\n",
                "total_samples = sum(class_counts)\n",
                "class_weights = [total_samples / count for count in class_counts]\n",
                "weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
                "\n",
                "# Loss with Label Smoothing\n",
                "criterion = nn.CrossEntropyLoss(weight=weights_tensor, label_smoothing=0.1)\n",
                "\n",
                "EPOCHS = 30\n",
                "LEARNING_RATE = 1e-4\n",
                "\n",
                "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
                "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5)\n",
                "\n",
                "# Save Directory\n",
                "os.makedirs('weights', exist_ok=True)\n",
                "\n",
                "best_val_acc = 0\n",
                "\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train()\n",
                "    train_loss = 0\n",
                "    train_correct = 0\n",
                "\n",
                "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{EPOCHS} - Train'):\n",
                "        images, labels = images.to(device), labels.to(device)\n",
                "\n",
                "        # Mixup\n",
                "        inputs, targets_a, targets_b, lam = mixup_data(images, labels, alpha=0.2, use_cuda=torch.cuda.is_available())\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        outputs = model(inputs)\n",
                "        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
                "        \n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        train_loss += loss.item()\n",
                "        _, predicted = torch.max(outputs.data, 1)\n",
                "        train_correct += (lam * predicted.eq(targets_a.data).cpu().sum().float() + \n",
                "                          (1 - lam) * predicted.eq(targets_b.data).cpu().sum().float())\n",
                "\n",
                "    train_acc = train_correct / len(train_dataset)\n",
                "\n",
                "    # Validation\n",
                "    model.eval()\n",
                "    val_loss = 0\n",
                "    val_correct = 0\n",
                "\n",
                "    with torch.no_grad():\n",
                "        for images, labels in tqdm(val_loader, desc=f'Epoch {epoch+1}/{EPOCHS} - Val'):\n",
                "            images, labels = images.to(device), labels.to(device)\n",
                "            outputs = model(images)\n",
                "            loss = criterion(outputs, labels)\n",
                "\n",
                "            val_loss += loss.item()\n",
                "            val_correct += (outputs.argmax(1) == labels).sum().item()\n",
                "\n",
                "    val_acc = val_correct / len(val_dataset)\n",
                "    scheduler.step(val_loss)\n",
                "\n",
                "    print(f'Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n",
                "    \n",
                "    # Save Checkpoint (Every Epoch)\n",
                "    torch.save(model.state_dict(), f'weights/model_epoch_{epoch+1}.pth')\n",
                "\n",
                "    # Save Best Model\n",
                "    if val_acc > best_val_acc:\n",
                "        best_val_acc = val_acc\n",
                "        torch.save(model.state_dict(), 'weights/best_waste_model.pth')\n",
                "        print(f'New best model saved! Accuracy: {val_acc:.4f}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}